"""
Simplified Streamlit web interface for deepfake detection research platform.
Works with basic dependencies only.
"""

import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import time
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from typing import Dict, List, Optional, Tuple
import io
import base64

# Import our simplified modules
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.simple_cnn_detector import create_simple_cnn_model
from utils.simple_preprocessing import SimpleFaceDetector, SimpleImagePreprocessor, SimpleVideoPreprocessor
from evaluation.simple_metrics import SimpleDetectionMetrics, SimpleRealTimeMetrics
# Import directly to avoid __init__.py issues
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from real_time_video_detector import RealTimeVideoDetector

# Page configuration
st.set_page_config(
    page_title="Deepfake Detection Research Platform",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class SimpleDeepfakeDetectionApp:
    """Simplified Streamlit application class."""
    
    def __init__(self):
        self.device = self._setup_device()
        self.models = {}
        self.current_model = None
        self.face_detector = None
        self.image_preprocessor = None
        self.video_preprocessor = None
        self.video_detector = None
        self.metrics = SimpleDetectionMetrics()
        self.realtime_metrics = SimpleRealTimeMetrics()
        
    def _setup_device(self):
        """Setup compute device."""
        if torch.cuda.is_available():
            return torch.device("cuda")
        elif torch.backends.mps.is_available():
            return torch.device("mps")
        else:
            return torch.device("cpu")
    
    def load_model(self, model_name: str, **kwargs):
        """Load a detection model."""
        try:
            model_key = f"simple_{model_name}"
            
            if model_key in self.models:
                self.current_model = self.models[model_key]
                return f"‚úÖ Model {model_key} already loaded"
            
            # Create model with only the model_name parameter
            model = create_simple_cnn_model(model_name, pretrained=True, **kwargs)
            model = model.to(self.device)
            model.eval()
            
            self.models[model_key] = model
            self.current_model = model
            self.model_name = model_name  # Store model name for video detection
            
            return f"‚úÖ {model_name.upper()} model loaded successfully on {self.device}"
            
        except Exception as e:
            return f"‚ùå Error loading model: {str(e)}"
    
    def setup_preprocessing(self):
        """Setup preprocessing components."""
        if self.face_detector is None:
            self.face_detector = SimpleFaceDetector(method="opencv")
        if self.image_preprocessor is None:
            self.image_preprocessor = SimpleImagePreprocessor()
        if self.video_preprocessor is None:
            self.video_preprocessor = SimpleVideoPreprocessor()
    
    def detect_deepfake(self, image: np.ndarray, confidence_threshold: float = 0.5) -> Dict:
        """Detect deepfake in image."""
        if self.current_model is None:
            return {
                'prediction': 'No model loaded',
                'confidence': 0.0,
                'is_fake': False,
                'error': 'Please load a model first'
            }
        
        try:
            self.setup_preprocessing()
            
            # Detect faces
            faces = self.face_detector.detect_faces(image)
            
            if not faces:
                return {
                    'prediction': 'No face detected',
                    'confidence': 0.0,
                    'is_fake': False,
                    'error': 'No face found in image'
                }
            
            # Use the largest face
            largest_face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_face
            
            # Extract face region
            face_region = image[y:y+h, x:x+w]
            
            # Preprocess face
            processed_face = self.image_preprocessor.preprocess_image(face_region)
            processed_face = processed_face.unsqueeze(0).to(self.device)
            
            # Make prediction
            with torch.no_grad():
                start_time = time.time()
                output = self.current_model(processed_face)
                inference_time = time.time() - start_time
                
                probabilities = torch.softmax(output, dim=1)
                prediction = torch.argmax(output, dim=1).item()
                confidence = torch.max(probabilities, dim=1)[0].item()
            
            return {
                'prediction': 'Fake' if prediction == 1 else 'Real',
                'confidence': confidence,
                'is_fake': prediction == 1,
                'inference_time': inference_time,
                'face_region': (x, y, w, h),
                'threshold_exceeded': confidence >= confidence_threshold
            }
            
        except Exception as e:
            return {
                'prediction': 'Error',
                'confidence': 0.0,
                'is_fake': False,
                'error': str(e)
            }
    
    def process_image(self, image: Image.Image, confidence_threshold: float) -> Tuple[str, Image.Image, str]:
        """Process uploaded image."""
        if image is None:
            return "No image provided", None, ""
        
        # Convert PIL to numpy
        image_np = np.array(image)
        
        # Make detection
        result = self.detect_deepfake(image_np, confidence_threshold)
        
        # Create result image with overlay
        result_image = image.copy()
        
        if 'face_region' in result and result['face_region']:
            x, y, w, h = result['face_region']
            
            # Draw face box
            if result['is_fake']:
                color = (255, 0, 0)  # Red for fake
            else:
                color = (0, 255, 0)  # Green for real
            
            # Convert PIL to OpenCV format for drawing
            cv_image = cv2.cvtColor(np.array(result_image), cv2.COLOR_RGB2BGR)
            cv2.rectangle(cv_image, (x, y), (x+w, y+h), color, 3)
            
            # Add label
            label = f"{result['prediction']} ({result['confidence']:.3f})"
            cv2.putText(cv_image, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # Convert back to PIL
            result_image = Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))
        
        # Create result text
        if 'error' in result:
            result_text = f"‚ùå Error: {result['error']}"
        else:
            status = "üö® FAKE DETECTED" if result['is_fake'] else "‚úÖ REAL IMAGE"
            result_text = f"{status}\nConfidence: {result['confidence']:.3f}\nInference Time: {result['inference_time']*1000:.1f}ms"
        
        return result_text, result_image, result['prediction']
    
    def detect_video_deepfake(self, video_file, confidence_threshold: float = 0.5) -> Dict:
        """Detect deepfake in video file."""
        if self.current_model is None:
            return {
                'error': 'No model loaded',
                'results': None
            }
        
        try:
            self.setup_preprocessing()
            
            # Save uploaded video temporarily
            temp_video_path = f"temp_video_{int(time.time())}.mp4"
            with open(temp_video_path, "wb") as f:
                f.write(video_file.getbuffer())
            
            # Initialize video detector
            model_name = getattr(self, 'model_name', 'resnet18')
            self.video_detector = RealTimeVideoDetector(
                model_name=model_name,
                confidence_threshold=confidence_threshold,
                temporal_window=5
            )
            self.video_detector.model = self.current_model
            
            # Process video
            results = self.video_detector.process_video_file(temp_video_path)
            
            # Clean up temp file
            import os
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
            
            return {
                'error': None,
                'results': results
            }
            
        except Exception as e:
            return {
                'error': str(e),
                'results': None
            }
    
    def start_realtime_detection(self, confidence_threshold: float = 0.5) -> bool:
        """Start real-time webcam detection."""
        if self.current_model is None:
            return False
        
        try:
            self.setup_preprocessing()
            
            # Initialize video detector
            self.video_detector = RealTimeVideoDetector(
                model_name=self.model_name if hasattr(self, 'model_name') else 'resnet18',
                confidence_threshold=confidence_threshold,
                temporal_window=5
            )
            self.video_detector.model = self.current_model
            
            # Start webcam detection
            return self.video_detector.start_webcam_detection()
            
        except Exception as e:
            print(f"Error starting real-time detection: {e}")
            return False
    
    def stop_realtime_detection(self):
        """Stop real-time webcam detection."""
        if self.video_detector:
            self.video_detector.stop_webcam_detection()
    
    def get_realtime_result(self) -> Dict:
        """Get current real-time detection result."""
        if self.video_detector:
            return self.video_detector.get_current_result()
        return {'error': 'No real-time detection active'}
    
    def create_performance_plot(self) -> go.Figure:
        """Create performance visualization."""
        # Simulate performance data
        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']
        values = [0.95, 0.93, 0.97, 0.95, 0.98]
        
        fig = go.Figure(data=[
            go.Bar(x=metrics, y=values, marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])
        ])
        
        fig.update_layout(
            title="Model Performance Metrics",
            xaxis_title="Metrics",
            yaxis_title="Score",
            yaxis=dict(range=[0, 1]),
            height=400
        )
        
        return fig

def main():
    """Main application function."""
    app = SimpleDeepfakeDetectionApp()
    
    # Header
    st.markdown('<h1 class="main-header">üîç Deepfake Detection Research Platform</h1>', 
                unsafe_allow_html=True)
    
    # Warning box
    st.markdown("""
    <div class="warning-box">
        <strong>‚ö†Ô∏è Research Platform Notice:</strong> This platform is designed for educational and research purposes only. 
        It focuses on developing detection algorithms to identify deepfakes and protect against malicious use.
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("üîß Configuration")
        
        # Model selection
        st.subheader("Model Selection")
        model_name = st.selectbox(
            "CNN Model",
            ["resnet18", "resnet34", "resnet50", "mobilenet_v2", "multiscale", "attention"],
            help="Select CNN architecture"
        )
        
        # Load model button
        if st.button("üîÑ Load Model", type="primary"):
            with st.spinner("Loading model..."):
                result = app.load_model(model_name)
                st.success(result)
        
        # Detection settings
        st.subheader("Detection Settings")
        confidence_threshold = st.slider(
            "Confidence Threshold",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="Minimum confidence for detection"
        )
        
        show_face_boxes = st.checkbox(
            "Show Face Detection Boxes",
            value=True,
            help="Display bounding boxes around detected faces"
        )
        
        # Device info
        st.subheader("System Info")
        st.info(f"üñ•Ô∏è Device: {app.device}")
        st.info(f"üêç Python: {sys.version.split()[0]}")
        st.info(f"üî• PyTorch: {torch.__version__}")
    
    # Main content area
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üì∏ Image Detection", 
        "üìπ Video Detection",
        "üìä Performance Analysis", 
        "üî¨ Model Comparison",
        "üìö Documentation"
    ])
    
    with tab1:
        st.header("üì∏ Image Deepfake Detection")
        
        if app.current_model is None:
            st.warning("‚ö†Ô∏è Please load a model first using the sidebar.")
        else:
            app.setup_preprocessing()
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("Upload Image")
                
                # File upload
                uploaded_file = st.file_uploader(
                    "Choose an image file",
                    type=['png', 'jpg', 'jpeg'],
                    help="Upload an image to analyze for deepfake detection"
                )
                
                # Camera input
                st.subheader("Or Use Camera")
                camera_input = st.camera_input("Take a photo")
                if camera_input:
                    uploaded_file = camera_input
            
            with col2:
                st.subheader("Detection Results")
                
                if uploaded_file is not None:
                    # Load and display image
                    image = Image.open(uploaded_file)
                    image_np = np.array(image)
                    
                    # Make detection
                    result = app.detect_deepfake(image_np, confidence_threshold)
                    
                    # Display results
                    if 'error' in result:
                        st.error(f"‚ùå {result['error']}")
                    else:
                        # Prediction result
                        if result['is_fake']:
                            st.error(f"üö® **FAKE DETECTED**")
                            st.error(f"Confidence: {result['confidence']:.3f}")
                        else:
                            st.success(f"‚úÖ **REAL IMAGE**")
                            st.success(f"Confidence: {result['confidence']:.3f}")
                        
                        # Additional info
                        st.info(f"‚è±Ô∏è Inference Time: {result['inference_time']*1000:.1f} ms")
                        
                        # Draw face box if requested
                        if show_face_boxes and 'face_region' in result:
                            x, y, w, h = result['face_region']
                            cv2.rectangle(image_np, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        
                        # Display image
                        st.image(image_np, caption="Analyzed Image", use_column_width=True)
    
    with tab2:
        st.header("üìπ Video Deepfake Detection")
        
        if app.current_model is None:
            st.warning("‚ö†Ô∏è Please load a model first using the sidebar.")
        else:
            app.setup_preprocessing()
            
            # Video detection options
            detection_mode = st.radio(
                "Detection Mode",
                ["üìÅ Upload Video File", "üìπ Real-time Webcam"],
                help="Choose between analyzing uploaded videos or real-time webcam detection"
            )
            
            if detection_mode == "üìÅ Upload Video File":
                st.subheader("Upload Video File")
                
                # Confidence threshold
                confidence_threshold = st.slider(
                    "Confidence Threshold", 
                    min_value=0.1, 
                    max_value=0.9, 
                    value=0.5, 
                    step=0.1,
                    help="Threshold for determining if a frame is fake"
                )
                
                # File upload
                uploaded_video = st.file_uploader(
                    "Choose a video file",
                    type=['mp4', 'avi', 'mov', 'mkv'],
                    help="Upload a video file to analyze for deepfake detection"
                )
                
                if uploaded_video is not None:
                    # Show video info
                    st.info(f"üìÅ **File**: {uploaded_video.name} ({uploaded_video.size / (1024*1024):.1f} MB)")
                    
                    # Process video
                    with st.spinner("üîÑ Processing video frames..."):
                        try:
                            result = app.detect_video_deepfake(uploaded_video, confidence_threshold)
                            
                            if result['error']:
                                st.error(f"‚ùå **Error**: {result['error']}")
                                st.info("üí° **Tips**: Make sure the video contains faces and is in a supported format (MP4, AVI, MOV, MKV)")
                            else:
                                results = result['results']
                                st.success("‚úÖ Video processing completed!")
                                
                                # Display summary
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("Total Frames", results['total_frames'])
                                with col2:
                                    st.metric("Processed Frames", results['processed_frames'])
                                with col3:
                                    st.metric("Fake Frames", results['fake_frames'])
                                with col4:
                                    st.metric("Real Frames", results['real_frames'])
                                
                                # Calculate overall video assessment
                                if results['processed_frames'] > 0:
                                    fake_percentage = (results['fake_frames'] / results['processed_frames']) * 100
                                    
                                    if fake_percentage > 50:
                                        st.error(f"üö® **VIDEO LIKELY FAKE** ({fake_percentage:.1f}% fake frames)")
                                    else:
                                        st.success(f"‚úÖ **VIDEO LIKELY REAL** ({fake_percentage:.1f}% fake frames)")
                                
                                # Temporal analysis
                                temporal = results['temporal_analysis']
                                st.subheader("Temporal Analysis")
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("Temporal Consistency", f"{temporal['temporal_consistency']:.3f}")
                                with col2:
                                    st.metric("Average Confidence", f"{temporal['avg_confidence']:.3f}")
                                
                                # Frame-by-frame results
                                st.subheader("Frame-by-Frame Results")
                                frame_data = []
                                for frame_result in results['frame_results'][:20]:  # Show first 20 frames
                                    frame_data.append({
                                        'Frame': frame_result['frame_number'],
                                        'Prediction': frame_result['prediction'],
                                        'Confidence': f"{frame_result['confidence']:.3f}",
                                        'Inference Time (ms)': f"{frame_result['inference_time']*1000:.1f}"
                                    })
                                
                                if frame_data:
                                    df = pd.DataFrame(frame_data)
                                    st.dataframe(df, use_container_width=True)
                                    
                        except Exception as e:
                            st.error(f"‚ùå **Unexpected Error**: {str(e)}")
                            st.info("üí° **Tips**: Try uploading a different video file or check if the file is corrupted")
            
            else:  # Real-time webcam
                st.subheader("Real-time Webcam Detection")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("üé• Start Webcam Detection", type="primary"):
                        if app.start_realtime_detection(confidence_threshold):
                            st.success("‚úÖ Webcam detection started!")
                            st.session_state['realtime_active'] = True
                        else:
                            st.error("‚ùå Failed to start webcam detection")
                
                with col2:
                    if st.button("‚èπÔ∏è Stop Webcam Detection"):
                        app.stop_realtime_detection()
                        st.session_state['realtime_active'] = False
                        st.success("‚úÖ Webcam detection stopped!")
                
                # Real-time results
                if st.session_state.get('realtime_active', False):
                    st.subheader("Real-time Results")
                    
                    # Update results
                    result = app.get_realtime_result()
                    
                    if 'error' not in result:
                        # Display current result
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            if result['is_fake']:
                                st.error("üö® **FAKE DETECTED**")
                            else:
                                st.success("‚úÖ **REAL**")
                        with col2:
                            st.metric("Confidence", f"{result['confidence']:.3f}")
                        with col3:
                            st.metric("Inference Time", f"{result['inference_time']*1000:.1f}ms")
                        
                        # Temporal analysis
                        temporal = result['temporal_analysis']
                        st.info(f"Temporal Consistency: {temporal['temporal_consistency']:.3f}")
                        
                        # Status indicator
                        st.success("üé• Webcam detection is active")
                        
                        # Manual refresh button
                        if st.button("üîÑ Refresh Results"):
                            st.rerun()
                    else:
                        st.warning("No detection results available")
                        st.info("Make sure your webcam is connected and accessible")
    
    with tab3:
        st.header("üìä Performance Analysis")
        
        if app.current_model is None:
            st.warning("‚ö†Ô∏è Please load a model first using the sidebar.")
        else:
            st.subheader("Model Performance Metrics")
            
            # Simulate some performance data for demo
            performance_data = {
                'Accuracy': 0.95,
                'Precision': 0.93,
                'Recall': 0.97,
                'F1-Score': 0.95,
                'ROC-AUC': 0.98
            }
            
            # Display metrics
            col1, col2, col3 = st.columns(3)
            for i, (metric, value) in enumerate(performance_data.items()):
                with [col1, col2, col3][i % 3]:
                    st.metric(metric, f"{value:.3f}")
            
            # Performance visualization
            st.subheader("Performance Visualization")
            
            # Create performance chart
            fig = app.create_performance_plot()
            st.plotly_chart(fig, use_container_width=True)
            
            # Model complexity info
            st.subheader("Model Information")
            
            total_params = sum(p.numel() for p in app.current_model.parameters())
            trainable_params = sum(p.numel() for p in app.current_model.parameters() if p.requires_grad)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Total Parameters", f"{total_params:,}")
            with col2:
                st.metric("Trainable Parameters", f"{trainable_params:,}")
    
    with tab3:
        st.header("üî¨ Model Comparison")
        
        st.subheader("Compare Different Models")
        
        # Model comparison interface
        comparison_models = st.multiselect(
            "Select models to compare",
            ["ResNet18", "ResNet34", "ResNet50", "MobileNet-V2", "Multi-Scale CNN", "Attention CNN"],
            default=["ResNet18", "ResNet50"]
        )
        
        if len(comparison_models) >= 2:
            # Simulate comparison data with correct length
            num_models = len(comparison_models)
            comparison_data = {
                'Model': comparison_models,
                'Accuracy': [0.95, 0.93, 0.96, 0.94, 0.97, 0.98][:num_models],
                'F1-Score': [0.95, 0.92, 0.95, 0.93, 0.96, 0.97][:num_models],
                'Inference Time (ms)': [45, 38, 120, 55, 85, 95][:num_models],
                'Memory Usage (MB)': [150, 120, 300, 180, 250, 280][:num_models]
            }
            
            # Create comparison chart
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=['Accuracy', 'F1-Score', 'Inference Time', 'Memory Usage'],
                specs=[[{"type": "bar"}, {"type": "bar"}],
                       [{"type": "bar"}, {"type": "bar"}]]
            )
            
            metrics = ['Accuracy', 'F1-Score', 'Inference Time (ms)', 'Memory Usage (MB)']
            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
            
            for i, metric in enumerate(metrics):
                row = i // 2 + 1
                col = i % 2 + 1
                
                fig.add_trace(
                    go.Bar(x=comparison_models, y=comparison_data[metric],
                          name=metric, marker_color=colors[i], showlegend=False),
                    row=row, col=col
                )
            
            fig.update_layout(
                title="Model Performance Comparison",
                height=600,
                showlegend=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Summary table
            st.subheader("Comparison Summary")
            df = pd.DataFrame(comparison_data)
            st.dataframe(df, use_container_width=True)
        else:
            st.warning("Please select at least 2 models to compare.")
    
    with tab5:
        st.header("üìö Documentation")
        
        st.subheader("About This Platform")
        
        st.markdown("""
        This Deepfake Detection Research Platform is designed to:
        
        - **Develop Detection Algorithms**: Create and test various deepfake detection methods
        - **Image Detection**: Analyze individual images for deepfake content
        - **Video Detection**: Process video files frame-by-frame for deepfake analysis
        - **Real-time Analysis**: Live webcam detection for real-time scenarios
        - **Temporal Analysis**: Analyze temporal consistency across video frames
        - **Performance Benchmarking**: Compare different models and approaches
        - **Educational Purpose**: Learn about deepfake technology and detection methods
        
        ### üî¨ Supported Models
        
        **CNN-based Models:**
        - ResNet18: Lightweight residual network
        - ResNet34: Medium-sized residual network
        - ResNet50: Classic convolutional architecture
        - MobileNet-V2: Efficient mobile architecture
        - Multi-Scale CNN: Detects artifacts at different scales
        - Attention CNN: Focuses on important regions
        
        ### üõ°Ô∏è Ethical Guidelines
        
        This platform is designed for:
        - ‚úÖ Research and education
        - ‚úÖ Developing detection algorithms
        - ‚úÖ Protecting against malicious deepfakes
        - ‚úÖ Understanding AI safety
        
        **Prohibited uses:**
        - ‚ùå Creating malicious deepfakes
        - ‚ùå Non-consensual image generation
        - ‚ùå Spreading misinformation
        - ‚ùå Harassment or fraud
        
        ### üìñ How to Use
        
        1. **Load a Model**: Select and load a detection model from the sidebar
        2. **Image Detection**: Upload images or use camera for detection
        3. **Video Detection**: Upload video files or use real-time webcam detection
        4. **Performance Analysis**: View model performance metrics
        5. **Model Comparison**: Compare different models
        
        ### üîß Technical Details
        
        - **Framework**: PyTorch
        - **Preprocessing**: OpenCV
        - **Interface**: Streamlit
        - **Visualization**: Plotly
        - **Device Support**: CPU, CUDA, MPS
        """)
        
        # Contact information
        st.subheader("üìû Contact & Support")
        
        st.markdown("""
        For questions, issues, or contributions:
        
        - üìß Email: research@deepfake-detection.org
        - üêõ Issues: GitHub Issues
        - üìñ Documentation: Full documentation available
        - ü§ù Contributing: See contribution guidelines
        """)
    
    # Footer
    st.markdown("""
    <div style="text-align: center; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;">
        <p>üîç Deepfake Detection Research Platform | Built for AI Safety Research</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
